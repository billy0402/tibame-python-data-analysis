{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 彩蛋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "import __hello__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import antigravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "from __future__ imports must occur at the beginning of the file (<ipython-input-4-6d5c5b2f0daf>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-6d5c5b2f0daf>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m from __future__ imports must occur at the beginning of the file\n"
     ]
    }
   ],
   "source": [
    "from __future__ import braces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...\n",
      "^C\n",
      "\n",
      "Keyboard interrupt received, exiting.\n"
     ]
    }
   ],
   "source": [
    "! python -m http.server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 語音辨識 及 輸出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [gTTS](https://pypi.org/project/gTTS/) (text to speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pipenv install gTTS\n",
    "# ! pipenv install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gtts-cli 'hello' --output hello.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "from pygame import mixer\n",
    "import tempfile\n",
    "\n",
    "mixer.init()\n",
    "\n",
    "def speak(sentence):\n",
    "    with tempfile.NamedTemporaryFile(delete=True) as file:\n",
    "        tts = gTTS(text=sentence, lang='zh-TW')\n",
    "        tts.save(\"{}.mp3\".format(file.name))\n",
    "        mixer.music.load('{}.mp3'.format(file.name))\n",
    "        mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請輸入問題: 你好\n"
     ]
    }
   ],
   "source": [
    "question_dict = {\n",
    "    '你好': '我很好',\n",
    "    '掰掰': '再見'\n",
    "}\n",
    "\n",
    "question = input('請輸入問題: ')\n",
    "reply = question_dict.get(question, '我現在還不聰明，等我變聰明了再告訴你')\n",
    "speak(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [SpeechRecognition](https://pypi.org/project/SpeechRecognition/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! brew install portaudio\n",
    "# ! pipenv install SpeechRecognition\n",
    "# ! pipenv install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition\n",
    "\n",
    "def listen():\n",
    "    recognizer = speech_recognition.Recognizer()\n",
    "\n",
    "    with speech_recognition.Microphone() as mic:\n",
    "        recognizer.adjust_for_ambient_noise(mic)\n",
    "        audio = recognizer.listen(mic)\n",
    "    recognizer.recognize_google(audio, language='zh-TW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_dict = {\n",
    "    '你好': '我很好',\n",
    "    '掰掰': '再見'\n",
    "}\n",
    "\n",
    "reply = question_dict.get(listen(), '我現在還不聰明，等我變聰明了再告訴你')\n",
    "speak(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 英文斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Alir3z4/stop-words/blob/master/english.txt\n",
    "with open('english_stop_words.txt', 'r') as file:\n",
    "    stop_words = file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('america', 17)\n",
      "('american', 12)\n",
      "('people', 9)\n",
      "('country', 9)\n",
      "('nation', 8)\n",
      "('president', 6)\n",
      "('protected', 5)\n",
      "('americans', 4)\n",
      "('citizens', 4)\n",
      "('power', 4)\n"
     ]
    }
   ],
   "source": [
    "with open('english_article.txt', 'r') as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "    symbol_list = [',', '.', '\\n', '’', '–']\n",
    "    for symbol in symbol_list:\n",
    "        text = text.replace(symbol, ' ')\n",
    "\n",
    "    word_list = text.split()\n",
    "    word_list = [word for word in word_list if word not in stop_words]\n",
    "\n",
    "    word_dict = dict()\n",
    "    for word in word_list:\n",
    "        if word not in word_dict:\n",
    "            word_dict[word] = 1\n",
    "        else:\n",
    "            word_dict[word] += 1\n",
    "\n",
    "    word_sort_list = sorted(word_dict.items(), key=lambda word_dict: word_dict[1], reverse=True)\n",
    "\n",
    "    for word in word_sort_list[:10]:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('america', 17),\n",
       " ('american', 12),\n",
       " ('people', 9),\n",
       " ('country', 9),\n",
       " ('nation', 8),\n",
       " ('president', 6),\n",
       " ('protected', 5),\n",
       " ('americans', 4),\n",
       " ('citizens', 4),\n",
       " ('power', 4)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "word_list = [word for word in re.split(\" |,|\\.|\\n|’|–\", \\\n",
    "                 open('english_article.txt', 'r').read().lower()) \\\n",
    "                 if word and word not in stop_words]\n",
    "Counter(word_list).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中文斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pipenv install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/goto456/stopwords/blob/master/中文停用词表.txt\n",
    "with open('chinese_stop_words.txt', 'r') as file:\n",
    "    stop_words = file.read().split('\\n')\n",
    "    stop_words.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/hs/0b8flhy51y374pl23g3f4bfw0000gn/T/jieba.cache\n",
      "Loading model cost 0.956 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('台灣', 25)\n",
      "('做', 12)\n",
      "('三年', 11)\n",
      "('一個', 9)\n",
      "('經濟', 9)\n",
      "('會', 8)\n",
      "('國家', 8)\n",
      "('長', 6)\n",
      "('必須', 6)\n",
      "('過去', 6)\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "with open('chinese_article.txt', 'r') as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "    word_list = jieba.cut(text)\n",
    "    word_list = [word for word in word_list if word not in stop_words]\n",
    "\n",
    "    word_dict = dict()\n",
    "    for word in word_list:\n",
    "        if word not in word_dict:\n",
    "            word_dict[word] = 1\n",
    "        else:\n",
    "            word_dict[word] += 1\n",
    "\n",
    "    word_sort_list = sorted(word_dict.items(), key=lambda word_dict: word_dict[1], reverse=True)\n",
    "\n",
    "    for word in word_sort_list[:10]:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('台灣', 25),\n",
       " ('做', 12),\n",
       " ('三年', 11),\n",
       " ('一個', 9),\n",
       " ('經濟', 9),\n",
       " ('會', 8),\n",
       " ('國家', 8),\n",
       " ('長', 6),\n",
       " ('必須', 6),\n",
       " ('過去', 6)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_list = [word for word in jieba.cut( \\\n",
    "                 open('chinese_article.txt', 'r').read().lower()) \\\n",
    "                 if word and word not in stop_words]\n",
    "Counter(word_list).most_common(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
